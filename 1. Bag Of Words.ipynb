{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python [conda env:Anaconda3]","language":"python","name":"conda-env-Anaconda3-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"name":"1. Bag Of Words.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"fHaVVmnJui0e","colab_type":"text"},"source":["# Bag Of Words(BoW)"]},{"cell_type":"markdown","metadata":{"id":"92bzDHAqui0g","colab_type":"text"},"source":["### Steps involved in BoW:"]},{"cell_type":"markdown","metadata":{"id":"kJjsedUhui0h","colab_type":"text"},"source":["#### 1. Construction of a d-dimensional dictionary "]},{"cell_type":"markdown","metadata":{"id":"gD6rIK4Mui0i","colab_type":"text"},"source":["- Here, we create an array of all the unique words in the document corpus.\n","- Let there be 'd' unique words.\n","- Every unique word is a dimension."]},{"cell_type":"markdown","metadata":{"id":"XFchSgeaui0k","colab_type":"text"},"source":["> **Note 1:** A text, which could be a word or a sentence, is known as a document in NLP."]},{"cell_type":"markdown","metadata":{"id":"wmVUBTVaui0l","colab_type":"text"},"source":["> **Note 2:** A collection of such documents is known as a document corpus."]},{"cell_type":"markdown","metadata":{"id":"lksYiYaVui0m","colab_type":"text"},"source":["#### 1.1 Example:"]},{"cell_type":"markdown","metadata":{"id":"7uUzgkrrui0o","colab_type":"text"},"source":["Let there be two documents in the document corpus as given below:\n","1. This car drives good and is expensive.\n","2. This car is not expensive and drives good.\n","\n","We create a dictionary(or an array) of all the unique words in the document corpus as:\n","\n","`[This, car, drives, good, and, is, expensive, not]`"]},{"cell_type":"markdown","metadata":{"id":"aEjD3Bteui0p","colab_type":"text"},"source":["#### 2. Creating vector for each document"]},{"cell_type":"markdown","metadata":{"id":"JfjF5Izfui0q","colab_type":"text"},"source":["- For every document we create a d-dimensional vector.\n","- Every dimension of a vector corresponds to a unique word.\n","- The value of every dimension is equivalent to the number of occurrences of the unique word, in the given document, corresponding to that dimension."]},{"cell_type":"markdown","metadata":{"id":"BYB7Upfpui0r","colab_type":"text"},"source":["> **Note 3:** Generally the BoW creates sparse vectors. In a sparse vector, most of the dimensions have 0 value."]},{"cell_type":"markdown","metadata":{"id":"_aw03E3hui0t","colab_type":"text"},"source":["#### 2.1 Example:"]},{"cell_type":"markdown","metadata":{"id":"w5A6vK0Gui0u","colab_type":"text"},"source":["Let vectors v<sub>1</sub> and v<sub>2</sub> correspond to document 1 and document 2 respectively. Then these vectors are represented as:\n","\n","v<sub>1</sub> = `[1 1 1 1 1 1 1 0]`\n","\n","v<sub>2</sub> = `[1 1 1 1 1 1 1 1]`"]},{"cell_type":"markdown","metadata":{"id":"VPyfA2-Iui0v","colab_type":"text"},"source":["#### 3. Calculating the distance between vectors"]},{"cell_type":"markdown","metadata":{"id":"TICjsOL2ui0x","colab_type":"text"},"source":["- The Euclidean distance is found between the vectors.\n","- Smaller Euclidean distance between the considered vectors corresponds to greater similarity between their corresponding documents.\n","- On the other hand, larger Euclidean distance between the considered vectors corresponds to lesser similarity between their corresponding documents."]},{"cell_type":"markdown","metadata":{"id":"FISVJjRpui0y","colab_type":"text"},"source":["#### 3.1 Example:"]},{"cell_type":"markdown","metadata":{"id":"u9sKgp6bui0z","colab_type":"text"},"source":["We calculate the Euclidean distance between v<sub>1</sub> and v<sub>2</sub> as:\n","\n","|v<sub>1</sub>-v<sub>2</sub>| = 1"]},{"cell_type":"markdown","metadata":{"id":"zAkVep0gui00","colab_type":"text"},"source":["### Binary BoW- Variation of BoW"]},{"cell_type":"markdown","metadata":{"id":"txII_fe9ui00","colab_type":"text"},"source":["- Here, the value of a dimension of a vector is either 0 or 1.\n","- The value is 1 if the occurrences of the unique word, corresponding to the dimension, is at least once and 0 otherwise.\n","- Binary BoW is also known as boolean BoW."]},{"cell_type":"markdown","metadata":{"id":"1W0xWYabuoNF","colab_type":"text"},"source":["#Implementation of BoW through Sklearn"]},{"cell_type":"code","metadata":{"id":"LVwivLsou_xF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593546416772,"user_tz":-330,"elapsed":875,"user":{"displayName":"Devesh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ6XJWpQ4PxGbIfBQD6NHOzIh2M2Dg1VmFfhJiaw=s64","userId":"15685909075934317041"}}},"source":["import pandas as pd\n","from sklearn.feature_extraction.text import CountVectorizer"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"JZuW8z1-vSEn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1593547058487,"user_tz":-330,"elapsed":1144,"user":{"displayName":"Devesh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ6XJWpQ4PxGbIfBQD6NHOzIh2M2Dg1VmFfhJiaw=s64","userId":"15685909075934317041"}},"outputId":"82390e40-31fe-4efd-eee7-80f78fd2fc39"},"source":["cv = CountVectorizer()\n","\n","corpus = ['This car drives good and is expensive',\n","          'This car is better than the other car and is less expensive and drives good']\n","\n","X = cv.fit(corpus) # cv.fit() creates the dictionary of all the unique words in the corpus.\n","print('Dictionary of all the unique words in the corpus:',X.vocabulary_)\n"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Dictionary of all the unique words in the corpus: {'this': 11, 'car': 2, 'drives': 3, 'good': 5, 'and': 0, 'is': 6, 'expensive': 4, 'better': 1, 'than': 9, 'the': 10, 'other': 8, 'less': 7}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l4mfRPdQwLlx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593547068323,"user_tz":-330,"elapsed":1023,"user":{"displayName":"Devesh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ6XJWpQ4PxGbIfBQD6NHOzIh2M2Dg1VmFfhJiaw=s64","userId":"15685909075934317041"}},"outputId":"73597550-94dc-4115-d758-74aa48850cf4"},"source":["print(cv.get_feature_names())"],"execution_count":20,"outputs":[{"output_type":"stream","text":["['and', 'better', 'car', 'drives', 'expensive', 'good', 'is', 'less', 'other', 'than', 'the', 'this']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CgxIW_vFwYHe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1593547072281,"user_tz":-330,"elapsed":1067,"user":{"displayName":"Devesh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ6XJWpQ4PxGbIfBQD6NHOzIh2M2Dg1VmFfhJiaw=s64","userId":"15685909075934317041"}},"outputId":"f7e04151-d6aa-4892-8d47-8304665022e2"},"source":["X = cv.transform(corpus)\n","print(X.toarray())"],"execution_count":21,"outputs":[{"output_type":"stream","text":["[[1 0 1 1 1 1 1 0 0 0 0 1]\n"," [2 1 2 1 1 1 2 1 1 1 1 1]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YBoZJ4MNwYot","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":106},"executionInfo":{"status":"ok","timestamp":1593547077199,"user_tz":-330,"elapsed":1339,"user":{"displayName":"Devesh Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ6XJWpQ4PxGbIfBQD6NHOzIh2M2Dg1VmFfhJiaw=s64","userId":"15685909075934317041"}},"outputId":"75185697-053e-4a04-cedc-778bf8bc0370"},"source":["df =pd.DataFrame(X.toarray(), columns = cv.get_feature_names())\n","df"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>and</th>\n","      <th>better</th>\n","      <th>car</th>\n","      <th>drives</th>\n","      <th>expensive</th>\n","      <th>good</th>\n","      <th>is</th>\n","      <th>less</th>\n","      <th>other</th>\n","      <th>than</th>\n","      <th>the</th>\n","      <th>this</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   and  better  car  drives  expensive  good  is  less  other  than  the  this\n","0    1       0    1       1          1     1   1     0      0     0    0     1\n","1    2       1    2       1          1     1   2     1      1     1    1     1"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"gz3uDq1Zy6Th","colab_type":"text"},"source":["In the above output we can see the number of times each unique word occurs in every document."]},{"cell_type":"markdown","metadata":{"id":"YJWs5nRtui01","colab_type":"text"},"source":["## Conclusion:"]},{"cell_type":"markdown","metadata":{"id":"Cs_6Qwi6ui02","colab_type":"text"},"source":["- Bag of words can be thought of as counting the differing words between vectors.\n","- Bag of words doesn't work well when there are subtle differences in words.\n","- That means BoW doesn't consider the semantic meaning of words. For example the words 'tasty' and 'delicious' are synonyms yet the BoW considers them different.\n","- Bag of words contains a lot of stopwords(which are trivial)."]},{"cell_type":"code","metadata":{"id":"P71xo9U3xLbd","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}